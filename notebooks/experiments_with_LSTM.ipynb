{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import argparse\n",
    "from random import shuffle\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torchnet.meter import AverageValueMeter\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'nb_epoch': 20,\n",
    "    'test_size': 0.1,\n",
    "    'learning_rate': 0.001,\n",
    "    'samples_per_epoch': 64,\n",
    "    'batch_size': 64,\n",
    "    'cuda': False,\n",
    "    'seed': 7\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**parser)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv('../data/C1-6_CanTho/C1/Training_Input.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.read_csv('../data/C1-6_CanTho/C1/Training_Target.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_df = pd.read_csv('../data/C1-6_CanTho/C1/Validation_Input.txt', sep='\\t', header=None)\n",
    "y_valid_df = pd.read_csv('../data/C1-6_CanTho/C1/Validation_target.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.read_csv('../data/C1-6_CanTho/C1/Testing_Input.txt', sep='\\t', header=None)\n",
    "y_test_df = pd.read_csv('../data/C1-6_CanTho/C1/Testing_Target.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        self.min = min(X)\n",
    "        self.max = max(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_norm = (self.X - self.min) / (self.max - self.min)\n",
    "        return X_norm\n",
    "    \n",
    "    def inverve_transform(self, X_norm):\n",
    "        X = X_norm * (self.max - self.min) + self.min\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreprapredData(X_df, y_df):\n",
    "    X_rainfall = copy.deepcopy(X_df[0].values)\n",
    "    X_current = copy.deepcopy(X_df[1].values)\n",
    "    \n",
    "    y = copy.deepcopy(y_df[0].values)\n",
    "    rainfall_normalizer = Normalizer()\n",
    "    current_normalizer = Normalizer()\n",
    "    rainfall_normalizer.fit(X_df[0].values)\n",
    "    current_normalizer.fit(X_df[1].values)\n",
    "\n",
    "    X_rainfall = rainfall_normalizer.transform(X_rainfall)\n",
    "    X_current = current_normalizer.transform(X_current)\n",
    "    y_normalized = current_normalizer.transform(y)\n",
    "    X_normalized = np.array(list(zip(X_rainfall, X_current)))\n",
    "    return X_normalized, y_normalized, current_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, y_train_normalized, train_current_normalizer = getPreprapredData(X_train_df, \n",
    "                                                           y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_normalized, y_valid_normalized, valid_current_normalizer = getPreprapredData(X_valid_df, \n",
    "                                                           y_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized, y_test_normalized, test_current_normalizer = getPreprapredData(X_test_df, \n",
    "                                                         y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_normalized = preprocessing.normalize(X_train_df.values, norm='l2')\n",
    "# y_train_normalized = preprocessing.normalize(y_train_df.values, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, X, y , is_training=True, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.is_training = is_training\n",
    "        # self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim*self.num_layers, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, x, cuda=False):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "#         lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "#         # Only take the output from the final timetep\n",
    "#         # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "#         y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "#         return y_pred.view(-1)\n",
    "    \n",
    "        tt = torch.cuda if cuda else torch\n",
    "        h = Variable(tt.FloatTensor(self.num_layers, x.size(1),self.hidden_dim).zero_(), requires_grad=False)\n",
    "        c = Variable(tt.FloatTensor(self.num_layers, x.size(1), self.hidden_dim).zero_(), requires_grad=False)\n",
    "        _, (h_t, c_t) = self.lstm(x, (h, c))\n",
    "        #h_t = F.tanh(h_t.squeeze(0))\n",
    "        #h_t = F.tanh(h_t)\n",
    "        out = torch.tanh(self.linear(h_t.view(-1, self.hidden_dim*self.num_layers)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WaterDataset(X_train_normalized, y_train_normalized)\n",
    "valid_dataset = WaterDataset(X_valid_normalized, y_valid_normalized)\n",
    "test_dataset = WaterDataset(X_test_normalized, y_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X = X.view(1, X.size(0), 2)\n",
    "        X, y = Variable(X.float()), Variable(y.float())\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        out = net(X)\n",
    "        loss = criterion(out, y.view(y.size(0), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "            \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Loss: %.3f '\n",
    "                % (train_loss/((batch_idx+1)*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid\n",
    "def valid(epoch, net, dataloader, criterion, use_cuda):\n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.view(1, X.size(0), 2)\n",
    "        X, y = Variable(X.float()), Variable(y.float())\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        out = net(X)\n",
    "        loss = criterion(out, y.view(y.size(0), 1))\n",
    "        valid_loss += loss.data.item()\n",
    "            \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Valid Loss: %.3f '\n",
    "                % (valid_loss/((batch_idx+1)*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSTM(2, 10, batch_size=args.batch_size, output_dim=1, num_layers=2)\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)\n",
    "\n",
    "if args.cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0, args.nb_epoch):\n",
    "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\t\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
    "    valid(epoch, net, valid_loader, criterion, args.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(net, dataloader, criterion, use_cuda):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    y_pred = []\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        X = X.view(1, X.size(0), 2)\n",
    "        X, y = Variable(X.float()), Variable(y.float())\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        out = net(X)\n",
    "        loss = criterion(out, y.view(y.size(0), 1))\n",
    "        test_loss += loss.data.item()\n",
    "        y_pred.extend(out.view(-1).detach().numpy())\n",
    "            \n",
    "    print('Test Loss: %.3f '\n",
    "                % (test_loss/((batch_idx+1)*3)))\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = test(net, test_loader, criterion, args.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_unnormalized = test_current_normalizer.inverve_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_unnormalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred_unnormalized)\n",
    "y_pred_df['index'] = y_pred_df.index\n",
    "y_test_df['index'] = y_test_df.index\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred_unnormalized, label='y_pred', color='blue')\n",
    "plt.plot(y_test_df[0].values, label='y_test', color='orange')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Test vs Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
