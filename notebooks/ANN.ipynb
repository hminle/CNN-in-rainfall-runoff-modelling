{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from random import shuffle\n",
    "import copy \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torchnet.meter import AverageValueMeter\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'nb_epoch': 15,\n",
    "    'test_size': 0.1,\n",
    "    'learning_rate': 0.001,\n",
    "    'samples_per_epoch': 64,\n",
    "    'batch_size': 64,\n",
    "    'cuda': False,\n",
    "    'seed': 17122018,\n",
    "    'dataset_dir': '../data',\n",
    "    'center': 'C1-6_CanTho',\n",
    "    'input_type': 'C1',\n",
    "    'output_dir': 'ANN_2_layers_normal_output/',\n",
    "    'model_arch': 'ANN_2_layers_normal',\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**parser)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "if args.input_type == 'C1':\n",
    "    args.input_features = 2\n",
    "elif args.input_type == 'C2':\n",
    "    args.input_features = 3\n",
    "elif args.input_type == 'C3':\n",
    "    args.input_features = 4\n",
    "elif args.input_type == 'C4':\n",
    "    args.input_features = 3\n",
    "elif args.input_type == 'C5':\n",
    "    args.input_features = 4\n",
    "else:\n",
    "    args.input_features = 5 # C6\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "else:\n",
    "    torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = args.dataset_dir + '/'+ args.center + '/' + args.input_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv(input_dir + '/Training_Input.txt', sep='\\t', header=None)\n",
    "y_train_df = pd.read_csv(input_dir + '/Training_Target.txt', sep='\\t', header=None)\n",
    "X_valid_df = pd.read_csv(input_dir + '/Validation_Input.txt', sep='\\t', header=None)\n",
    "y_valid_df = pd.read_csv(input_dir + '/Validation_target.txt', sep='\\t', header=None)\n",
    "X_test_df = pd.read_csv(input_dir + '/Testing_Input.txt', sep='\\t', header=None)\n",
    "y_test_df = pd.read_csv(input_dir + '/Testing_Target.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        self.min = np.min(X)\n",
    "        self.max = np.max(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_norm = (X - self.min) / (self.max - self.min)\n",
    "        return X_norm\n",
    "    \n",
    "    def inverve_transform(self, X_norm):\n",
    "        X = X_norm * (self.max - self.min) + self.min\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreprapredData(X_df, y_df, input_type):\n",
    "    if input_type in ['C1', 'C2', 'C5']:\n",
    "        X_rainfall = copy.deepcopy(X_df[0].values)\n",
    "        X_rainfall = X_rainfall.reshape(X_rainfall.shape[0], 1)\n",
    "\n",
    "        X_current = copy.deepcopy(X_df).drop(columns=[0]).values\n",
    "\n",
    "        y = copy.deepcopy(y_df[0].values)\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        current_stack = np.column_stack((X_current, y))\n",
    "\n",
    "        rainfall_normalizer = Normalizer()\n",
    "        current_normalizer = Normalizer()\n",
    "\n",
    "        rainfall_normalizer.fit(X_rainfall)\n",
    "        current_normalizer.fit(current_stack)\n",
    "\n",
    "        X_rainfall = rainfall_normalizer.transform(X_rainfall)\n",
    "        X_current = current_normalizer.transform(X_current)\n",
    "        y_normalized = current_normalizer.transform(y)\n",
    "        X_normalized = np.column_stack((X_rainfall, X_current))\n",
    "        #X_normalized = X_current\n",
    "        return X_normalized, y_normalized, current_normalizer\n",
    "    else:\n",
    "        X_rainfall = copy.deepcopy(X_df[[0, 1]].values)\n",
    "        #X_rainfall = X_rainfall.reshape(X_rainfall.shape[0], 1)\n",
    "\n",
    "        X_current = copy.deepcopy(X_df).drop(columns=[0, 1]).values\n",
    "\n",
    "        y = copy.deepcopy(y_df[0].values)\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        current_stack = np.column_stack((X_current, y))\n",
    "\n",
    "        rainfall_normalizer = Normalizer()\n",
    "        current_normalizer = Normalizer()\n",
    "\n",
    "        rainfall_normalizer.fit(X_rainfall)\n",
    "        current_normalizer.fit(current_stack)\n",
    "\n",
    "        X_rainfall = rainfall_normalizer.transform(X_rainfall)\n",
    "        X_current = current_normalizer.transform(X_current)\n",
    "        y_normalized = current_normalizer.transform(y)\n",
    "        X_normalized = np.column_stack((X_rainfall, X_current))\n",
    "        return X_normalized, y_normalized, current_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, X, y , is_training=True, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.is_training = is_training\n",
    "        # self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class ANN_2_layers_residual(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features=1, batch_size=64, \n",
    "                 output_dim=1, center='C1-6_CanTho'):\n",
    "        super(ANN_2_layers_residual, self).__init__()\n",
    "        self.input_features = input_features\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.ann_net = nn.Sequential(\n",
    "            nn.Linear(input_features, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(64 + input_features,\n",
    "                                output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, X, cuda=False):\n",
    "        #X = X.view(X.size(0), 1, X.size(1)) # TODO: check it again\n",
    "        out = self.ann_net(X)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        #out = out.view(X.size(0), -1)\n",
    "        # out = out + X[:, :, -1]\n",
    "        out = torch.cat((out, X.view(X.size(0), -1)), dim=1)\n",
    "        out = torch.tanh(self.linear(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class ANN_2_layers_normal(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features=1, batch_size=64, \n",
    "                 output_dim=1, center='C1-6_CanTho'):\n",
    "        super(ANN_2_layers_normal, self).__init__()\n",
    "        self.input_features = input_features\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.ann_net = nn.Sequential(\n",
    "            nn.Linear(input_features, 64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(64,\n",
    "                                output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "    def forward(self, X, cuda=False):\n",
    "        #X = X.view(X.size(0), 1, X.size(1)) # TODO: check it again\n",
    "        out = self.ann_net(X)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        #out = out.view(X.size(0), -1)\n",
    "        # out = out + X[:, :, -1]\n",
    "        #out = torch.cat((out, X.view(X.size(0), -1)), dim=1)\n",
    "        out = torch.tanh(self.linear(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class TwoLayerUsualCNN_C1(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel=1, layer1_out=32, layer2_out=64, batch_size=64, length_of_signal=2, kernel_size=2,\n",
    "                    output_dim=1):\n",
    "        super(TwoLayerUsualCNN_C1, self).__init__()\n",
    "        self.input_channel = input_channel\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channel, layer1_out, kernel_size=kernel_size, stride=2),\n",
    "            nn.BatchNorm1d(layer1_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=kernel_size, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(layer1_out, layer2_out, kernel_size=kernel_size, stride=2),\n",
    "            nn.BatchNorm1d(layer2_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=kernel_size, stride=2))\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(layer2_out + length_of_signal,\n",
    "                                output_dim)\n",
    "\n",
    "    def forward(self, X, cuda=False):\n",
    "        X = X.view(X.size(0), 1, X.size(1)) # TODO: check it again\n",
    "        out = self.layer1(X)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(X.size(0), -1)\n",
    "        # out = out + X[:, :, -1]\n",
    "        out = torch.cat((out, X.view(X.size(0), -1)), dim=1)\n",
    "        out = torch.tanh(self.linear(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        #X = X.view(1, X.size(0), 2)\n",
    "        #X = X.view(X.size(0), 1, X.size(1))\n",
    "        X, y = Variable(X.float()), Variable(y.float())\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        out = net(X)\n",
    "        loss = criterion(out, y.view(y.size(0), 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Loss: %.3f '\n",
    "                % (train_loss/((batch_idx+1)*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test(net, dataloader, criterion, use_cuda):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    y_pred = []\n",
    "    for batch_idx, (X, y) in enumerate(dataloader):\n",
    "        #X = X.view(1, X.size(0), 2)\n",
    "        #X = X.view(X.size(0), 1, X.size(1))\n",
    "        X, y = Variable(X.float()), Variable(y.float())\n",
    "        if use_cuda:\n",
    "            X, y = X.cuda(), y.cuda()\n",
    "        out = net(X)\n",
    "        loss = criterion(out, y.view(y.size(0), 1))\n",
    "        test_loss += loss.data.item()\n",
    "        y_pred.extend(out.view(-1).detach().numpy())\n",
    "            \n",
    "    #print('Test Loss: %.3f ' % (test_loss/((batch_idx+1)*3)))\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized, y_train_normalized, train_current_normalizer = getPreprapredData(X_train_df, \n",
    "                                                           y_train_df, args.input_type)\n",
    "X_valid_normalized, y_valid_normalized, valid_current_normalizer = getPreprapredData(X_valid_df, \n",
    "                                                           y_valid_df, args.input_type)\n",
    "X_test_normalized, y_test_normalized, test_current_normalizer = getPreprapredData(X_test_df, \n",
    "                                                         y_test_df, args.input_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.center == 'C1-6_ChauDoc':\n",
    "    X_test_normalized[428:429, 0] = 0.02741021  # Chau Doc\n",
    "else:\n",
    "    X_test_normalized[397:398, 0] = 0 # Can Tho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WaterDataset(X_train_normalized, y_train_normalized)\n",
    "valid_dataset = WaterDataset(X_valid_normalized, y_valid_normalized)\n",
    "test_dataset = WaterDataset(X_test_normalized, y_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#net = ANN(input_features=args.input_features, batch_size=64)\n",
    "if args.model_arch == 'ANN_2_layers_normal':\n",
    "    net = ANN_2_layers_normal(input_features=args.input_features, batch_size=64)\n",
    "elif args.model_arch == 'ANN_2_layers_residual':\n",
    "    net = ANN_2_layers_residual(input_features=args.input_features, batch_size=64)\n",
    "#net = TwoLayerCNN_TwoFC(1, layer1_cnn_out=32, layer2_cnn_out=64, layer1_fc_out=64, batch_size=args.batch_size, length_of_signal=args.length_of_signal)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.1, rho=0.9, eps=1e-06, weight_decay=1e-05)\n",
    "#optimizer = optim.Adadelta(net.parameters(), lr=0.1, rho=0.9, eps=1e-06)\n",
    "#optimizer = optim.Adagrad(net.parameters(), lr=0.01, lr_decay=1e-05, weight_decay=1e-05, initial_accumulator_value=0)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0, dampening=0, weight_decay=0)\n",
    "#optimizer = optim.Adamax(net.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "if args.cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "epoch_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load('TwoLayerUsualCNN_32_64_C1-6_CanTho_C5.pkl')\n",
    "#checkpoint = torch.load('TwoLayerUsualCNN_16_32_C1-6_ChauDoc_C2.pkl')\n",
    "#net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 15):\n",
    "    epoch_count += 1\n",
    "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\t\n",
    "    print('\\nEpoch: %d' % epoch_count)\n",
    "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
    "    #valid(epoch, net, valid_loader, criterion, args.cuda)\n",
    "    \n",
    "    y_pred_train = test(net, train_loader, criterion, args.cuda)\n",
    "    y_pred_train_unnormalized = train_current_normalizer.inverve_transform(y_pred_train)\n",
    "    train_rmse = math.sqrt(mean_squared_error(y_train_df[0].values, y_pred_train_unnormalized))\n",
    "    \n",
    "    y_pred_valid = test(net, valid_loader, criterion, args.cuda)\n",
    "    y_pred_valid_unnormalized = valid_current_normalizer.inverve_transform(y_pred_valid)\n",
    "    valid_rmse = math.sqrt(mean_squared_error(y_valid_df[0].values, y_pred_valid_unnormalized))\n",
    "    \n",
    "    print('Train RMSE: %.3f -- Valid RMSE: %.3f ' % (train_rmse, valid_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSE\n",
    "y_pred = test(net, test_loader, criterion, args.cuda)\n",
    "y_pred_unnormalized = test_current_normalizer.inverve_transform(y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test_df[0].values, y_pred_unnormalized))\n",
    "r2Score = r2_score(y_test_df[0].values, y_pred_unnormalized)\n",
    "mae = mean_absolute_error(y_test_df[0].values, y_pred_unnormalized)\n",
    "print('R2: %.3f -- RMSE: %.3f -- MAE: %.3f' % (r2Score, rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred_unnormalized)\n",
    "y_pred_df['index'] = y_pred_df.index\n",
    "y_test_df['index'] = y_test_df.index\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6] # Discharge vs Time\n",
    "#plt.rcParams['figure.figsize'] = [6, 6] # Predicted vs Observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw discharge vs time\n",
    "x = list(range(len(y_pred_unnormalized)))\n",
    "plt.plot(x, y_pred_unnormalized, label='Predicted', color='red', linestyle='dashed', linewidth=0.5)\n",
    "plt.plot(x, y_test_df[0].values, label='Observed', color='blue', linewidth=0.5)\n",
    "plt.legend(loc='upper left')\n",
    "#plt.title('CNN Model - Test vs Prediction', fontdict={'fontsize': 18})\n",
    "plt.xlabel('Time (day)', fontdict={'fontsize': 14})\n",
    "plt.ylabel('Discharge (m\\u00b3/s)', fontdict={'fontsize': 14})\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0), useMathText=True)\n",
    "plt.yticks([0, 2000, 4000, 6000, 8000, 10000]) #Chau Doc\n",
    "#plt.yticks([0, 5000, 10000, 15000, 20000]) #Can Tho\n",
    "image_file_name = '{}_{}_{}.jpg'.format(args.model_arch, args.center, args.input_type)\n",
    "#plt.savefig(image_file_name, dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw predicted and observed discharge\n",
    "x = list(range(len(y_pred_unnormalized)))\n",
    "plt.plot(y_test_df[0].values,y_test_df[0].values, color='black')\n",
    "plt.scatter(y_test_df[0].values, y_pred_unnormalized, label='Predicted', color='blue', )\n",
    "#plt.legend(loc='upper left')\n",
    "#plt.title('CNN Model - Test vs Prediction', fontdict={'fontsize': 18})\n",
    "plt.xlabel('Observed discharge (m\\u00b3/s)', fontdict={'fontsize': 14})\n",
    "plt.ylabel('Predicted discharge (m\\u00b3/s)', fontdict={'fontsize': 14})\n",
    "plt.xticks([0, 2000, 4000, 6000, 8000]) # Chau Doc\n",
    "#plt.ticklabel_format(axis='both', style='sci', scilimits=(0,0), useMathText=True)\n",
    "#plt.xticks([0, 5000, 10000, 15000, 20000]) #Can Tho\n",
    "#plt.yticks([0, 5000, 10000, 15000, 20000]) #Can Tho\n",
    "image_file_name_2 = '{}_{}_{}_predicted_vs_observed.jpg'.format(args.model_arch, args.center, args.input_type)\n",
    "#plt.savefig(image_file_name_2, dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "            'center': args.center,\n",
    "            'input_type': args.input_type,\n",
    "            'model_arch': args.model_arch,\n",
    "            'optimizer_arch': 'optim.Adam(net.parameters(), lr=0.01)',\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'valid_rmse': valid_rmse,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{}_{}_{}.pkl'.format(args.model_arch, args.center, args.input_type)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./ANN_normal_2th_C1-6_CanTho_C1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSE\n",
    "y_pred = test(net_loaded, test_loader, criterion, args.cuda)\n",
    "y_pred_unnormalized = test_current_normalizer.inverve_transform(y_pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test_df[0].values, y_pred_unnormalized))\n",
    "r2_score = r2_score(y_test_df[0].values, y_pred_unnormalized)\n",
    "mae = mean_absolute_error(y_test_df[0].values, y_pred_unnormalized)\n",
    "print('RMSE: %.3f -- R2_score: %.3f -- MAE: %.3f' % (rmse, r2_score, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized[390:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred_unnormalized, label='y_pred', color='blue')\n",
    "plt.plot(y_test_df[0].values, label='y_test', color='orange')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('CNN Model - Test vs Prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
